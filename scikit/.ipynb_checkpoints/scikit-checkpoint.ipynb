{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab101b50",
   "metadata": {},
   "source": [
    "## Introduction to scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3a406",
   "metadata": {},
   "source": [
    "What we going to cover\n",
    "\n",
    "0. [An end-to-end Scikit-Learn workflow](#0.-An-end-to-end-Scikit-Learn-workflow)\n",
    "1. [Getting the data ready](#1.-Getting-the-data-ready-to-be-used-with-machine-learning)\n",
    "2. [Choose the right estimator/algorithm for our problems](#2.-Chosing-right-estimator-or-algorithm-for-your-problem)\n",
    "3. [Fit the model/algorithm and use it to make predictions on our data](#3.-Fit-the-model/algorithm-and-use-it-to-make-predictions-on-our-data)\n",
    "4. [Evaluating a model](#4.-Evaluating-a-model)\n",
    "    1. [Notes](#Notes)\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together!\n",
    "\n",
    "\n",
    "\n",
    "**Links for Feature Scaling**\n",
    "1. __[https://rahul-saini.medium.com/feature-scaling-why-it-is-required-8a93df1af310](https://rahul-saini.medium.com/feature-scaling-why-it-is-required-8a93df1af310)__\n",
    "2. __[https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)__\n",
    "3. __[https://benalexkeen.com/feature-scaling-with-scikit-learn/](https://benalexkeen.com/feature-scaling-with-scikit-learn/)__\n",
    "\n",
    "**Links for ROC and AUC**\n",
    "1. __[https://www.youtube.com/watch?v=4jRBRDbJemM](https://www.youtube.com/watch?v=4jRBRDbJemM)__\n",
    "2. __[https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)__\n",
    "\n",
    "**Which model to choose - Scikit learn Cheat sheet**\n",
    "* __[https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)__\n",
    "\n",
    "**Check this for Google's Courses**\n",
    "1. __[https://developers.google.com/machine-learning/foundational-courses](https://developers.google.com/machine-learning/foundational-courses)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac09775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46d4f8c2",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f751c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data ready\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "heart_disease = pd.read_csv('../data/heart-disease.csv')\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5380896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (feature matrix)\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "\n",
    "# create y (labels)\n",
    "y = heart_disease['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d1e020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. choose right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ff9b7",
   "metadata": {},
   "source": [
    "### 3 . fit the model to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9a1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042e19e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd862bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/.local/lib/python3.8/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 2. 3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# it wont work bcz the model is trained on different data format\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:821\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:863\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    861\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    866\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:603\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 603\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 2. 3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "y_label = clf.predict(np.array([1,2,3])) # it wont work bcz the model is trained on different data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0793a3",
   "metadata": {},
   "source": [
    "### 4 .Evaluate the model on training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e046556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30345324",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a189f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "print(classification_report(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc892f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a7fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c10a8c",
   "metadata": {},
   "source": [
    "### 5. Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Training model with {i} estimator..\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set : {clf.score(x_test, y_test)*100:.2f}%\")\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda167a",
   "metadata": {},
   "source": [
    "### 6 . Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510038cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50).fit(X_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open(\"randm_forest.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbe75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"randm_forest.pkl\", 'rb'))\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf132eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f4e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd94a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec785540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2586c012",
   "metadata": {},
   "source": [
    "# DETAILED OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fad95b",
   "metadata": {},
   "source": [
    "## 1. Getting the data ready to be used with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7365005",
   "metadata": {},
   "source": [
    "\n",
    "Three main things:\n",
    "1. Split the data into features and labels(usually `X` and `y`\n",
    "2. Filling (also called imputing) or disregarding missing value\n",
    "3. Non-numeric value to numeric (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset to training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,y,test_size=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f747f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af122b",
   "metadata": {},
   "source": [
    "### 1.1 Make it all numerical (Feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48310b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv('../data/car-sales-extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faef1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d40cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X = car_sales.drop('Price', axis = 1)\n",
    "y = car_sales['Price']\n",
    "\n",
    "# Splitting to Train and Test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18d986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Building machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales['Doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the categories to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#here we can also convert doors column since it is categorical\n",
    "categorical_features  = ['Make', 'Colour','Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                               remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e14917",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694eea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "\n",
    "np.random.seed(22)\n",
    "X_train, x_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d6524",
   "metadata": {},
   "source": [
    "### ================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2375689",
   "metadata": {},
   "source": [
    "### 1.2 What if there are missing values?\n",
    "1. Fill them with some value(also known as imputation)\n",
    "2. Remove the samples with missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a744752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv('../data/car-sales-extended-missing-data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert text to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = car_sales_missing.drop('Price', axis=1)\n",
    "y = car_sales_missing['Price']\n",
    "\n",
    "\n",
    "#here we can also convert doors column since it is categorical\n",
    "categorical_features  = ['Make', 'Colour','Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "transformed_X = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9b245",
   "metadata": {},
   "source": [
    "### Option 1 : Filling missing values with panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7db412",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing['Doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing['Make'].fillna(\"missing\", inplace=True)\n",
    "car_sales_missing['Colour'].fillna(\"missing\", inplace=True)\n",
    "car_sales_missing['Odometer (KM)'].fillna(car_sales_missing['Odometer (KM)'].mean(), inplace=True)\n",
    "car_sales_missing['Doors'].fillna(4, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12587bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66280359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do remove the missing values for price since without it, it is harder to predict\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf11ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1937e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca190fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert text to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = car_sales_missing.drop('Price', axis=1)\n",
    "y = car_sales_missing['Price']\n",
    "\n",
    "\n",
    "#here we can also convert doors column since it is categorical\n",
    "categorical_features  = ['Make', 'Colour','Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "transformed_X = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4edb7",
   "metadata": {},
   "source": [
    "### Option 2 : Filling missing value with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv('../data/car-sales-extended-missing-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c387b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758f6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "car_sales_missing.dropna(subset=['Price'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7d563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_sales_missing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f37f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = car_sales_missing.drop('Price', axis=1)\n",
    "y = car_sales_missing['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Filling categorical values with 'missing' & numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value = 4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#Define columns\n",
    "cat_features = ['Make', 'Colour']\n",
    "door_features = ['Doors']\n",
    "num_features = ['Odometer (KM)']\n",
    "\n",
    "\n",
    "#Create an imputer (something tht fills up the data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer,cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_features),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "filled_X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sale_filled = pd.DataFrame(filled_X, columns=['Make', 'Colour', 'Odometer (KM)', 'Doors'])\n",
    "car_sale_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert text to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# X = car_sales_missing.drop('Price', axis=1)\n",
    "# y = car_sales_missing['Price']\n",
    "\n",
    "\n",
    "#here we can also convert doors column since it is categorical\n",
    "categorical_features  = ['Make', 'Colour','Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "transformed_X = transformer.fit_transform(car_sale_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36847b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Train the values\n",
    "np.random.seed(32)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, y_train,y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7350c609",
   "metadata": {},
   "source": [
    "## 2. Chosing right estimator or algorithm for your problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f0f28",
   "metadata": {},
   "source": [
    "Sklearn refer machine learning algorithm and models as ***Estimators***\n",
    "\n",
    "Cheat_sheet - __[https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "911cd379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50056784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5380b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c28cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['Target'] = housing['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9403b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996224dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "np.random.seed(42)\n",
    "\n",
    "X= housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bbc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f95587",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "np.random.seed(42)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459ed04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "np.random.seed(42)\n",
    "model = SVR()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a23ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using a Randomforest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "X= housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c99e2",
   "metadata": {},
   "source": [
    "## 2.2 Choosing an estimator for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716ff8e",
   "metadata": {},
   "source": [
    "**Let's go to the map...** https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31c2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv('../data/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be58add",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d2be5",
   "metadata": {},
   "source": [
    "\n",
    "**Consulting the map and it says to use `LinearSVC`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bdb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# setting up the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the Data\n",
    "X = heart_disease.drop('target', axis =1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# Split the data\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the LinearSVC\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0caad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b6dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setting up the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the Data\n",
    "X = heart_disease.drop('target', axis =1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# Split the data\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the LinearSVC\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bc1ca",
   "metadata": {},
   "source": [
    "## 3. Fit the model/algorithm and use it to make predictions on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c88c1",
   "metadata": {},
   "source": [
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for\n",
    "* `X` = features, features variables, data\n",
    "* `y` = labels, target variables, target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44915af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setting up the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the Data\n",
    "X = heart_disease.drop('target', axis =1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# Split the data\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac07c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data (Training the machine learning model)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f79466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Evaluate the LinearSVC( Use the patterns model has learnt)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25748d54",
   "metadata": {},
   "source": [
    "### 3.2 Make predictions using machine learning model\n",
    "2 ways to make predictions\n",
    "1. `predict()`\n",
    "2. `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff086e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e7d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79cf8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = clf.predict(x_test)\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3871813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9586cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b411e16",
   "metadata": {},
   "source": [
    "**Making prediction using `predict_proba()`**\n",
    "* It gives the probability of the class (confidence in which class the answer will be `0` or `1`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c1dbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(x_test[:5])\n",
    "#Below values gives the confidence that model has over the data. \n",
    "#Let say if there are less difference between 2 classes, then there is a confusion for the model to predict\n",
    "# i.e it is hard to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f5f0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260a1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32f3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create a data\n",
    "X = housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "# Split to train and test data\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "#Create model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predction\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce844f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebe6707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1e565",
   "metadata": {},
   "source": [
    "**Keywords - Regression metric evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd206d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the prediction with truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e627a06",
   "metadata": {},
   "source": [
    "## 4. Evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8135fe7",
   "metadata": {},
   "source": [
    "Three ways to evaluate a `Models` /`Estimator`:\n",
    "1. [Estimator's builtin `score()` method](#4.1-Evaluating-model-with-score()-method)\n",
    "2. [The `Scoring` parameter](#4.2-Evaluating-model-using-scoring-parameter)\n",
    "    1.  [4.2.1 Classification model evaluataion metrics](#4.2.1-Classification-model-evaluataion-metrics)\n",
    "    2.  [4.2.2 Regression model evaluation metrics](#4.2.2-Regression-model-evaluation-metrics)\n",
    "    3.  [Notes](#Notes-Machine-Learning-Model-Evaluation)\n",
    "    4.  [4.2.3 Finally evaluating using Scoring parameter](#4.2.3-Finally-evaluating-using-Scoring-parameter)\n",
    "3. [Problem specific metric funtions](#4.3-Problem-specific-metric-funtions---Using-different-metrics-as-Scikit-Learn-functions)\n",
    "\n",
    "Links - \n",
    "1. https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b65438",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating model with score() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3481cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "979ab192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create X and y\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "#Create train and test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "#Create Classifier model instance\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93bb37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa77645",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a3b87",
   "metadata": {},
   "source": [
    "**Lets use `score()` for Regression problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9964ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc637d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create X and y\n",
    "X = housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "#Create train and test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "#Create Classifier model instance\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97395232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "765f6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default score() evaluation metric is R_squared for regression algorithms\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416146cc",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating model using scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62c22ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create X and y\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "#Create train and test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "#Create Classifier model instance\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70768a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab6e653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a444840",
   "metadata": {},
   "source": [
    "![](../images/sklearn-cross-validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba181a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default scoring parameter of classifier = mean accuracy\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03c5a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5) # scoring paramete set to None by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53410389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1393fee",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluataion metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595d3e0",
   "metadata": {},
   "source": [
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da3a02",
   "metadata": {},
   "source": [
    "**1. Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a501d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X= heart_disease.drop('target', axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score =cross_val_score(clf, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be928c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec474bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Heart Disease Classifier Cross_Validated Accuracy : {np.mean(cross_val_score) * 100:2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5da2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4acade",
   "metadata": {},
   "source": [
    "**2 . Area Under the Receiver Operating Characteristic Curve (AUC / ROC)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b37a2",
   "metadata": {},
   "source": [
    "* Area Under Curve (AUC)\n",
    "* ROC curve\n",
    "\n",
    "ROC curve are a comparision of a model's true positive rate(tpr) versus a model's false positive rate(fpr)\n",
    "\n",
    "    * True positive =  model predicts 1 when truth is 1\n",
    "    * False positive =  model predicts 1 when truth is 0    \n",
    "    * True negative =  model predicts 0 when truth is 0    \n",
    "    * False negative =  model predicts 0 when truth is 1    \n",
    "    \n",
    "ROC curves and AUC metrics are evaluation metrics for binary classification models (a model which predicts one thing or another, such as heart disease or not).\n",
    "\n",
    "The ROC curve compares the true positive rate (tpr) versus the false positive rate (fpr) at different classification thresholds.\n",
    "\n",
    "The AUC metric tells you how well your model is at choosing between classes (for example, how well it is at deciding whether someone has heart disease or not). A perfect model will get an AUC score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a507462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7feef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "\n",
    "y_prob[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0457d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_positive = y_prob[:,1] # take all the column 1 of every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "918f2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tpr and fpr and thresholds\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47180e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check false positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fcf244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb6c3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plot ROC curve from given false positive rate (fpr)\n",
    "    and true positive rate(tpr)\n",
    "    \"\"\"\n",
    "    \n",
    "    #plot ROC curve\n",
    "    plt.plot(fpr, tpr, color= \"orange\", label= \"ROC\")\n",
    "    \n",
    "    #plot the baseline (no predicting power)\n",
    "    plt.plot([0,1], [0,1], color= \"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "    \n",
    "    #customize the plot\n",
    "    plt.xlabel(\"False poitive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characterisitcs (ROC) curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef7350fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f585c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting threshold\n",
    "plt.plot(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f94c977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score #plotting for Area under curve\n",
    "roc_auc_score(y_test, y_prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52aa9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try for perfect score that roc gives. WHere there is no false positive\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03de9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544441cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92c26a2a",
   "metadata": {},
   "source": [
    "**3. Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f14705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc7f494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, y_preds, rownames=[\"Actual_label\"], colnames=[\"predicted_lables\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc792f",
   "metadata": {},
   "source": [
    "![](../images/sklearn-confusion-matrix-anatomy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72b8f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make our confusion matrix more visual with seaborn's heatmap()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#set font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c2d97",
   "metadata": {},
   "source": [
    "**Create confusion matx using scikit library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f948ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SKlearn's inbuilt method\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y) # using itself create a prediction from X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58a16d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf2db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7fcda4",
   "metadata": {},
   "source": [
    "**4. Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0df5da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318aa587",
   "metadata": {},
   "source": [
    "![](../images/ClassificationReportAnatomy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08343c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ec307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d21dfe3",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97957968",
   "metadata": {},
   "source": [
    "1. R^2 (R-squared) or Coeff of determination\n",
    "2. Mean Absolute Error\n",
    "3. Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73a4a9",
   "metadata": {},
   "source": [
    "**R-squared**\n",
    "\n",
    "What R-squared does: Compares your model prediction to the mean of the targets, Values can range from negative infinity(a very poor model) to 1. \n",
    "\n",
    "For example,\n",
    "* If all your model does is predict the mean of the target, Its R^2 value be 0.  \n",
    "* If your model perfectly predicts a range of numbers it's R^2 value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15f1cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "730b4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "housing_df['target'] = housing['target']\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de63ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "220fc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Fill array with y_test_mean\n",
    "\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15fb584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f2d47",
   "metadata": {},
   "source": [
    "**Mean Absolute Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9b6b3",
   "metadata": {},
   "source": [
    "It is a absolute mean of differences predicted and actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa78d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(x_test) \n",
    "y_pred\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8347c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual':y_test, 'Pred': y_pred})\n",
    "df['Diff'] = np.abs(df['Pred']-df['Actual'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a7f05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df['Diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9956734",
   "metadata": {},
   "source": [
    "**Mean Square Error** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fa717",
   "metadata": {},
   "source": [
    "\n",
    "It is a mean of the square of the errors between actual and predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "526e4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f871a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sqrd_diff'] = np.square(df['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68019699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fb0f9",
   "metadata": {},
   "source": [
    "### Notes-Machine Learning Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b5216",
   "metadata": {},
   "source": [
    "**Machine Learning Model Evaluation**\n",
    "\n",
    "Evaluating the results of a machine learning model is as important as building one.\n",
    "\n",
    "But just like how different problems have different machine learning models, different machine learning models have different evaluation metrics.\n",
    "\n",
    "Below are some of the most important evaluation metrics you'll want to look into for classification and regression models.\n",
    "\n",
    "**1. Classification Model Evaluation Metrics/Techniques**\n",
    "\n",
    "* Accuracy - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\n",
    "\n",
    "* Precision - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "\n",
    "* Recall - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "\n",
    "* F1 score - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "\n",
    "* Confusion matrix - Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagonal line).\n",
    "\n",
    "* Cross-validation - Splits your dataset into multiple parts and train and tests your model on each part then evaluates performance as an average.\n",
    "\n",
    "* Classification report - Sklearn has a built-in function called classification_report() which returns some of the main classification metrics such as precision, recall and f1-score.\n",
    "\n",
    "* ROC Curve - Also known as receiver operating characteristic is a plot of true positive rate versus false-positive rate.\n",
    "\n",
    "* Area Under Curve (AUC) Score - The area underneath the ROC curve. A perfect model achieves an AUC score of 1.0.\n",
    "\n",
    "**Which classification metric should you use?**\n",
    "\n",
    "* Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1).\n",
    "\n",
    "* Precision and recall become more important when classes are imbalanced.\n",
    "\n",
    "* If false-positive predictions are worse than false-negatives, aim for higher precision.\n",
    "\n",
    "* If false-negative predictions are worse than false-positives, aim for higher recall.\n",
    "\n",
    "* F1-score is a combination of precision and recall.\n",
    "\n",
    "* A confusion matrix is always a good way to visualize how a classification model is going.\n",
    "\n",
    "**2. Regression Model Evaluation Metrics/Techniques**\n",
    "\n",
    "* R^2 (pronounced r-squared) or the coefficient of determination - Compares your model's predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.\n",
    "\n",
    "* Mean absolute error (MAE) - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "\n",
    "* Mean squared error (MSE) - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "\n",
    "**Which regression metric should you use?**\n",
    "\n",
    "* R2 is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your R2 value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "\n",
    "* MAE gives a better indication of how far off each of your model's predictions are on average.\n",
    "\n",
    "* As for MAE or MSE, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
    "\n",
    "* Pay more attention to MAE: When being `10,000` off is twice as bad as being `5,000` off.\n",
    "\n",
    "* Pay more attention to MSE: When being 10,000 off is more than twice as bad as being 5,000 off.\n",
    "\n",
    "* For more resources on evaluating a machine learning model, be sure to check out the following resources:\n",
    "\n",
    "Scikit-Learn documentation for metrics and scoring (quantifying the quality of predictions)\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Beyond Accuracy: Precision and Recall by Will Koehrsen \n",
    "* https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c\n",
    "\n",
    "Stack Overflow answer describing MSE (mean squared error) and RSME (root mean squared error)\n",
    "* https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python/37861832#37861832"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf040e5",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally evaluating using `Scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebb7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(24)\n",
    "\n",
    "heart_disease = pd.read_csv('../data/heart-disease.csv')\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis =1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a21f1",
   "metadata": {},
   "source": [
    "link - https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3629b7",
   "metadata": {},
   "source": [
    "**for Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f0f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy :82.48%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#cross_validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, scoring=None) #default scoring is accuracy\n",
    "\n",
    "print(f'Cross validation accuracy :{np.mean(cv_acc)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199ccf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82352941, 0.93548387, 0.84848485, 0.79411765, 0.76315789])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision\n",
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, scoring=\"precision\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c80b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation precision :83.30%\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross validation precision :{np.mean(cv_acc)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a868fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87878788, 0.84848485, 0.78787879, 0.81818182, 0.87878788])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "cv_acc = cross_val_score(clf, X, y, scoring=\"recall\")\n",
    "cv_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d56d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation precision :84.24%\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross validation precision :{np.mean(cv_acc)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0a388",
   "metadata": {},
   "source": [
    "**for Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6269f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c532243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62138178, 0.72415528, 0.62584522])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "model= RandomForestRegressor()\n",
    "\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7617684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571274240862545"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4853da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50673632, -0.33699591, -0.53581597])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Squared Error\n",
    "\n",
    "cv_MSE = cross_val_score(model, X, y, cv =3 , scoring=\"neg_mean_squared_error\")\n",
    "cv_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84ab195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4598494034955272"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41039f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51870334, -0.42287944, -0.50177401])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Absolute Error\n",
    "\n",
    "cv_MAE = cross_val_score(model, X, y, cv =3 , scoring=\"neg_mean_absolute_error\")\n",
    "cv_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "538d1359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4811189318168605"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe97f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a3b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2228008",
   "metadata": {},
   "source": [
    "### 4.3 Problem specific metric funtions - Using different metrics as Scikit-Learn functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab3d4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics on test set\n",
      "Accuracy : 81.97\n",
      "Precision Score : 0.8\n",
      "Recall : 0.875\n",
      "F1 : 0.8358208955223881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#create X & y\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "#split Train, test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Initialise Model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print('Classifier metrics on test set')\n",
    "print(f'Accuracy : {accuracy_score(y_test, y_pred)*100:.2f}')\n",
    "print(f'Precision Score : {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall : {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 : {f1_score(y_test, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa231830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.816445544531211\n",
      "MAE : 0.3262880367490312\n",
      "MSE : 0.24722413661678516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create X & y\n",
    "X= housing_df.drop('Target', axis=1)\n",
    "y = housing_df['Target']\n",
    "\n",
    "#Split train and test set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Initialize the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluate\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')\n",
    "print(f'MAE : {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'MSE : {mean_squared_error(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a734f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
